services:
  # AI
  ollama:
    image: ollama/ollama
    container_name: ollama
    volumes:
      - "{{ appdata_path }}/apps/ollama:/root/.ollama"
    ports:
      - 11434:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: cdi
              capabilities:
                - gpu
              device_ids:
                - nvidia.com/gpu=all
    restart: unless-stopped
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    volumes:
      - "{{ appdata_path }}/apps/open-webui:/app/backend/data"
    labels:
      - traefik.enable=true
      - traefik.http.routers.ollamawebui.rule=Host(`ollama.{{ nv_wd_domain_me }}`)
    ports:
      - 8080:8080
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    restart: unless-stopped
  ebook2audiobookxtts:
    image: athomasson2/ebook2audiobookxtts:huggingface
    container_name: ebook2audiobookxtts
    tty: true
    stdin_open: true
    ports:
      - 7860:7860
    command: python app.py
    deploy:
      resources:
        reservations:
          devices:
            - driver: cdi
              capabilities:
                - gpu
              device_ids:
                - nvidia.com/gpu=all
    restart: unless-stopped