---

target_os: proxmox

# zfs
# created as raidz for 18Tb of available storage
# zpool create backups raidz /dev/disk/by-id/ata-WDC_WD100EMAZ-00WJTA0_16G0Z7RZ /dev/disk/by-id/ata-WDC_WD100EMAZ-00WJTA0_16G10VZZ /dev/disk/by-id/ata-WDC_WD100EMAZ-00WJTA0_2YJ2S3AD

# grog.package
package_list:
  - name: bash-completion
  - name: curl
  - name: fio
  - name: git
  - name: hddtemp
  - name: htop
  - name: iftop
  - name: iotop
  - name: lm-sensors
  - name: mc
  - name: ncdu
  - name: net-tools
  - name: nfs-kernel-server
  - name: nmap
  - name: ssh
  #- name: open-vm-tools #vmware
  - name: python
  - name: qemu-guest-agent
  - name: sanoid
  - name: smartmontools
  - name: sudo
  - name: tmux
  - name: tree
  - name: wget
  #- name: zfs-linux

# ironicbadger.bash-aliases (formerly ferrarimarco.bash-aliases)
bash_aliases:
  - { alias: "dtail", command: "docker logs -tf --tail='50' " }
  - { alias: "dstop", command: "docker stop `docker ps -aq`" }
  - { alias: "drm", command: "docker rm `docker ps -aq`" }
  - { alias: "dcp", command: "docker-compose -f ~/docker-compose.yml "}
  - { alias: "dcporph", command: "docker-compose -f ~/docker-compose.yml up -d --remove-orphans"}
  - { alias: "dprune", command: "docker image prune" }
  - { alias: "dprunesys", command: "docker system prune --all" }
  - { alias: "dtop", command: "docker run --name ctop  -it --rm -v /var/run/docker.sock:/var/run/docker.sock quay.io/vektorlab/ctop"}
  - { alias: "zspace", command: "zfs list -o space" }
  - { alias: "zsnap", command: "zfs list -o space | sort -k4 --human-numeric-sort" }
  - { alias: "dfclean", command: "df -h -x tmpfs -t fuse.mergerfs -t xfs -t ext4"}
  - { alias: "dffull", command: "df -h -x tmpfs -t fuse.mergerfs -t xfs -t ext4 -t zfs"}
  - { alias: "hdtemp", command: "sudo hddtemp -q /dev/sd[a,b,c,d,e,f,g,h,i,j,k,l,m,n]"}

# ktz-sanoid
sanoid_config_source: sanoid-morpheus.conf
syncoid_hc_url: "/usr/bin/curl -fsS --retry 3 https://hc.{{ domain_cloud }}/ping"

syncoid_cron_jobs:
  - { job: '{{ syncoid_hc_url }}/{{ syncoid_backup_healthcheck_uuid_tank }}/start && {{ syncoid_binary_path }} -r alex@m:tank backups/morpheus/tank | {{ syncoid_hc_url }}/{{ syncoid_backup_healthcheck_uuid_tank }} --data-binary "@-"', 
      name: 'morpheus_tank_replication', 
      weekday: '*', 
      hour: '*',
      minute: '14' }
#   - { job: '{{ syncoid_binary_path }} -r alex@m:intel2tbnvme backups/morpheus/intel2tbnvme && {{ syncoid_hc_url }}/{{ syncoid_backup_healthcheck_uuid_intel2tbnvme }} --data-binary "@-"', 
#       name: 'morpheus_intel2tbnvme_replication', 
#       weekday: '*', 
#       hour: '*',
#       minute: '30' }
  - { job: '{{ syncoid_hc_url }}/{{ syncoid_backup_healthcheck_uuid_ssd500_mirror }}/start && {{ syncoid_binary_path }} -r alex@m:ssd500-mirror backups/morpheus/ssd500-mirror | {{ syncoid_hc_url }}/{{ syncoid_backup_healthcheck_uuid_ssd500_mirror }} --data-binary "@-"', 
      name: 'morpheus_ssd500_mirror_replication', 
      weekday: '*', 
      hour: '*',
      minute: '45' }
  - { job: '{{ syncoid_hc_url }}/{{ syncoid_backup_healthcheck_uuid_nvme2tb }}/start && {{ syncoid_binary_path }} -r alex@m:nvme2tb backups/morpheus/nvme2tb | {{ syncoid_hc_url }}/{{ syncoid_backup_healthcheck_uuid_nvme2tb }} --data-binary "@-"', 
      name: 'morpheus_nvme2tb_replication', 
      weekday: '*', 
      hour: '*',
      minute: '55' }